# create_marketing_retriever.py
# -*- coding: utf-8 -*-

import os
import time
from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
# [ë³€ê²½] Google ëŒ€ì‹  HuggingFace ì„ë² ë”©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from langchain_community.embeddings import HuggingFaceEmbeddings
# [ì‚­ì œ] from dotenv import load_dotenv (ë” ì´ìƒ í•„ìš” ì—†ìŒ)

def create_and_save_retriever():
    """
    (ìˆ˜ì •ë¨) ë¡œì»¬ Hugging Face ì„ë² ë”© ëª¨ë¸('dragonkue/BGE-m3-ko')ì„ ì‚¬ìš©í•˜ì—¬
    ë§ˆì¼€íŒ… PDF ë¬¸ì„œë¡œë¶€í„° Retrieverë¥¼ ìƒì„±í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    try:
        # 0. [ë³€ê²½] API í‚¤ ë¡œë”© ë¡œì§ ì‚­ì œ
        print("âœ… ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (API í‚¤ í•„ìš” ì—†ìŒ)")

        # 1. ë°ì´í„° ë¡œë“œ
        loader = DirectoryLoader(
            './marketing',
            glob="**/*.pdf",
            loader_cls=PyPDFLoader,
            show_progress=True,
            use_multithreading=True
        )
        documents = loader.load()
        print(f"âœ… ì´ {len(documents)}ê°œì˜ PDF ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

        if not documents:
            raise ValueError("ğŸš¨ 'marketing' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")

        # 2. í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100
        )
        docs = text_splitter.split_documents(documents)
        print(f"âœ… ë¬¸ì„œë¥¼ ì´ {len(docs)}ê°œì˜ ì²­í¬(chunk)ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")

        if not docs:
            raise ValueError("ğŸš¨ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        # 3. [ë³€ê²½] ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        print(f"âœ… ì„ë² ë”© ëª¨ë¸ 'dragonkue/BGE-m3-ko' ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        model_name = "dragonkue/BGE-m3-ko"
        # ğŸ’¡ [ì°¸ê³ ] ë¡œì»¬ PC/ì„œë²„ì— GPUê°€ ìˆë‹¤ë©´ {'device': 'cuda'}ë¡œ ë³€ê²½í•˜ì„¸ìš”.
        model_kwargs = {'device': 'cpu'} 
        # ğŸ’¡ [ì¤‘ìš”] BGE ëª¨ë¸ì€ ê²€ìƒ‰ ì„±ëŠ¥ì„ ìœ„í•´ ì •ê·œí™”(normalize)ë¥¼ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤.
        encode_kwargs = {'normalize_embeddings': True}

        embeddings = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs=model_kwargs,
            encode_kwargs=encode_kwargs
        )
        print(f"âœ… ì„ë² ë”© ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

        # 4. Vector Store ìƒì„± (FAISS)
        vectorstore = None
        
        # [ë³€ê²½] ë¡œì»¬ ëª¨ë¸ì€ ë°°ì¹˜ ì²˜ë¦¬ê°€ ë§¤ìš° ë¹ ë¥´ë¯€ë¡œ, API ì œí•œ(time.sleep)ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
        # [ì°¸ê³ ] BGE-m3-ko ëª¨ë¸ì€ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ì§€ì›í•˜ë¯€ë¡œ, FAISS.from_documentsê°€ ë‚´ë¶€ì ìœ¼ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        print(f"ğŸ”„ ì´ {len(docs)}ê°œì˜ ì²­í¬ì— ëŒ€í•œ ì„ë² ë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤. (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ)")
        
        vectorstore = FAISS.from_documents(docs, embeddings)

        # 5. [ë³€ê²½] ë¡œì»¬ ì €ì¥ (ê²½ë¡œëŠ” ë™ì¼)
        save_dir = './retriever/marketing_retriever' # [ê²½ë¡œ ìˆ˜ì •] knowledge_base.pyì™€ ë§ì¶¤
        os.makedirs(save_dir, exist_ok=True)

        vectorstore.save_local(save_dir)

        print(f"ğŸ‰ Retrieverê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì–´ '{save_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        print(f"ğŸš¨ğŸš¨ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ ğŸš¨ğŸš¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    # 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
    try:
        import langchain_community
        import sentence_transformers
        import faiss
        import torch
    except ImportError as e:
        print(f"ğŸš¨ [ì˜¤ë¥˜] {e.name} ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ‘‰ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
        print("pip install langchain-community sentence-transformers faiss-cpu torch")
        print("(GPU ì‚¬ìš© ì‹œ: pip install langchain-community sentence-transformers faiss-gpu torch)")
        exit(1)
        
    create_and_save_retriever()